# TorIntel (Dark Web Monitoring Tool)

This tool scans the dark web for potential leaks of sensitive information. It connects to the Tor network and scrapes hidden services (.onion sites) to detect if an organization's data is exposed.

## Project Structure
```
 dark-web-monitoring-tool/
 ├── dark_web_monitoring/
 │   ├── __init__.py
 │   ├── main.py           # Main script to start scanning
 │   ├── scraper.py        # Module responsible for web scraping
 │   ├── config.py         # Configuration settings (Tor proxy, URLs, etc.)
 │   ├── utils.py          # Utility functions (logging, parsing, etc.)
 │   ├── requirements.txt  # Dependencies list
 ├── logs/                 # Logs for scanning sessions
 ├── README.md             # Documentation (this file)
 ├── requirements.txt      # List of required Python packages
 ├── .gitignore            # Git ignore file
```

## Features
- Connects to the Tor network using a SOCKS5 proxy.
- Scrapes specified .onion sites for sensitive data.
- Logs findings and errors for review.
- Configurable list of target websites.

## Installation
### Prerequisites
- Python 3.7+
- Tor installed and running (with SOCKS5 proxy enabled on port 9050)

### Setup
1. Clone the repository:
   ```bash
   git clone https://github.com/your-repo/dark-web-monitoring-tool.git
   cd dark-web-monitoring-tool
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Start the Tor service:
   ```bash
   tor
   ```
   Ensure Tor is listening on `127.0.0.1:9050`.

## Usage
Run the monitoring tool:
```bash
python dark_web_monitoring/main.py
```
The script will scan the configured .onion sites and log potential leaks.

## Configuration
Modify `config.py` to:
- Add new .onion sites for monitoring.
- Change the logging settings.
- Adjust proxy settings.

## Troubleshooting
### Error: "Failed to establish a new connection"
- Ensure Tor is running and listening on port `9050`.
- Verify your network connection.

### Error: "expected string or bytes-like object, got 'dict'"
- Check `scraper.py` for improper handling of response data.
- Ensure the target sites are accessible and returning valid HTML.

## License
This project is licensed under the MIT License.

## Disclaimer
This tool is for educational and research purposes only. The author is not responsible for any misuse.

